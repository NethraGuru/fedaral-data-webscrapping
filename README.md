# Web Scraping and Data Cleaning Project

## ğŸ“Œ Overview
This project scrapes a dynamically loaded table from a JavaScript-rendered webpage using **Playwright**, extracts the data, and then processes it with **Pandas** to retain only the last 10 years of relevant records.

## ğŸ“¦ Requirements
- **Python 3.8+** installed
- **Google Chrome** or Chromium-based browser installed

## ğŸ“ Project Structure
```
.
â”œâ”€â”€ data/                   # Data files
â”‚   â”œâ”€â”€ raw/               # Raw scraped data
â”‚   â””â”€â”€ processed/         # Cleaned and processed data
â”œâ”€â”€ docs/                  # Documentation files
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ src/                  # Source code
â””â”€â”€ requirements.txt      # Project dependencies
```

## ğŸ›  Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone <your-repo-url>
cd <your-repo-directory>
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip3 install -r requirements.txt
```

### 3ï¸âƒ£ Create a Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate
```

### 4ï¸âƒ£ Install Playwright Browsers
```bash
python3 -m playwright install
```

## ğŸš€ Running the Project

urls = {
    'Federal_Funds_Rate': 'https://fred.stlouisfed.org/data/FEDFUNDS.txt',
    '1_Year_Treasury_Rate': 'https://fred.stlouisfed.org/data/GS1.txt',
    '10_Year_Treasury_Rate': 'https://fred.stlouisfed.org/data/GS10.txt'
}

#### 1ï¸âƒ£ Run the Scripts
```bash
python3 src/federal_rate_web_scrapping.py 'url1' 'url2' 'url3'
python3 src/clean_data.py data/table_data_*.csv
```

## Next Steps
- [ ] Data Analysis using a Notebook in notebooks/rate_analysis_stats.ipynb
